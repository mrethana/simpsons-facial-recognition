{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import re\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bart_dir = 'data/bart/'\n",
    "data_marge_dir = 'data/marge/'\n",
    "data_homer_dir = 'data/homer/'\n",
    "data_lisa_dir = 'data/lisa/'\n",
    "data_ned_dir = 'data/ned/'\n",
    "data_moe_dir = 'data/moe/'\n",
    "data_krusty_dir = 'data/krusty/'\n",
    "data_skinner_dir = 'data/skinner/'\n",
    "data_charles_dir = 'data/charles/'\n",
    "data_milhouse_dir = 'data/milhouse/'\n",
    "data_other_dir = 'data/other/'\n",
    "new_dir = 'split/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [file.replace('.jpg','') for file in os.listdir('simpson_test_set/')]\n",
    "list_names = set([re.sub('[0-9]+', '', file) for file in x])\n",
    "list_names = list(list_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs_bart = [file for file in os.listdir('simpson_test_set/') if file.startswith('bart_simpson')]\n",
    "test_imgs_homer = [file for file in os.listdir('simpson_test_set/') if file.startswith('homer_simpson')]\n",
    "test_imgs_marge = [file for file in os.listdir('simpson_test_set/') if file.startswith('marge_simpson')]\n",
    "test_imgs_lisa = [file for file in os.listdir('simpson_test_set/') if file.startswith('lisa_simpson')]\n",
    "test_imgs_moe = [file for file in os.listdir('simpson_test_set/') if file.startswith('moe_szyslak')]\n",
    "test_imgs_ned = [file for file in os.listdir('simpson_test_set/') if file.startswith('ned_flanders')]\n",
    "test_imgs_krusty = [file for file in os.listdir('simpson_test_set/') if file.startswith('krusty_the_clown')]\n",
    "test_imgs_skinner = [file for file in os.listdir('simpson_test_set/') if file.startswith('principal_skinner')]\n",
    "test_imgs_charles = [file for file in os.listdir('simpson_test_set/') if file.startswith('charles_montgomery_burns')]\n",
    "test_imgs_milhouse = [file for file in os.listdir('simpson_test_set/') if file.startswith('milhouse_van_houten')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_test =[test_imgs_bart, test_imgs_homer, test_imgs_marge, test_imgs_lisa ,test_imgs_moe,test_imgs_ned,test_imgs_krusty,test_imgs_skinner,test_imgs_charles,test_imgs_milhouse]\n",
    "all_characters_test = []\n",
    "for character in character_test:\n",
    "    all_characters_test.extend(character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs_other = [file for file in os.listdir('simpson_test_set/') if file not in all_characters_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(test_imgs_bart))\n",
    "# print(len(test_imgs_homer))\n",
    "# print(len(test_imgs_marge))\n",
    "# print(len(test_imgs_lisa))\n",
    "# print(len(test_imgs_moe))\n",
    "# print(len(test_imgs_ned))\n",
    "# print(len(test_imgs_krusty))\n",
    "# print(len(test_imgs_skinner))\n",
    "# print(len(test_imgs_charles))\n",
    "# print(len(test_imgs_milhouse))\n",
    "# print(len(test_imgs_other))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_bart = [file for file in os.listdir('simpsons_training_set/bart_simpson/')]\n",
    "train_imgs_homer = [file for file in os.listdir('simpsons_training_set/homer_simpson/')]\n",
    "train_imgs_marge = [file for file in os.listdir('simpsons_training_set/marge_simpson/')]\n",
    "train_imgs_lisa = [file for file in os.listdir('simpsons_training_set/lisa_simpson/')]\n",
    "train_imgs_moe = [file for file in os.listdir('simpsons_training_set/moe_szyslak/')]\n",
    "train_imgs_ned = [file for file in os.listdir('simpsons_training_set/ned_flanders/')]\n",
    "train_imgs_krusty = [file for file in os.listdir('simpsons_training_set/krusty_the_clown/')]\n",
    "train_imgs_skinner = [file for file in os.listdir('simpsons_training_set/principal_skinner/')]\n",
    "train_imgs_charles = [file for file in os.listdir('simpsons_training_set/charles_montgomery_burns/')]\n",
    "train_imgs_milhouse = [file for file in os.listdir('simpsons_training_set/milhouse_van_houten/')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_train = ['charles_montgomery_burns','milhouse_van_houten','moe_szyslak','ned_flanders','krusty_the_clown','marge_simpson','principal_skinner','bart_simpson','lisa_simpson', 'homer_simpson','.DS_Store']\n",
    "train_images_other = []\n",
    "for folder in os.listdir('simpsons_training_set/'):\n",
    "    if folder not in character_train:\n",
    "        for file in os.listdir('simpsons_training_set/'+folder):\n",
    "            train_images_other.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340\n",
      "2246\n",
      "1291\n",
      "1354\n",
      "1450\n",
      "1454\n",
      "1206\n",
      "1194\n",
      "1193\n",
      "1079\n",
      "7156\n"
     ]
    }
   ],
   "source": [
    "print(len(train_imgs_bart))\n",
    "print(len(train_imgs_homer))\n",
    "print(len(train_imgs_marge))\n",
    "print(len(train_imgs_lisa))\n",
    "print(len(train_imgs_moe))\n",
    "print(len(train_imgs_ned))\n",
    "print(len(train_imgs_krusty))\n",
    "print(len(train_imgs_skinner))\n",
    "print(len(train_imgs_charles))\n",
    "print(len(train_imgs_milhouse))\n",
    "print(len(train_images_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'split/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0d1f8d3cb245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'split/'"
     ]
    }
   ],
   "source": [
    "os.mkdir(new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = os.path.join(new_dir, 'train')\n",
    "train_bart = os.path.join(train_folder, 'bart')\n",
    "train_homer = os.path.join(train_folder, 'homer')\n",
    "train_marge = os.path.join(train_folder, 'marge')\n",
    "train_lisa = os.path.join(train_folder, 'lisa')\n",
    "train_moe = os.path.join(train_folder, 'moe')\n",
    "train_ned = os.path.join(train_folder, 'ned')\n",
    "train_krusty = os.path.join(train_folder, 'krusty')\n",
    "train_skinner = os.path.join(train_folder, 'skinner')\n",
    "train_charles = os.path.join(train_folder, 'charles')\n",
    "train_milhouse = os.path.join(train_folder, 'milhouse')\n",
    "train_other = os.path.join(train_folder, 'other')\n",
    "\n",
    "test_folder = os.path.join(new_dir, 'test')\n",
    "test_bart = os.path.join(test_folder, 'bart')\n",
    "test_homer = os.path.join(test_folder, 'homer')\n",
    "test_marge = os.path.join(test_folder, 'marge')\n",
    "test_lisa = os.path.join(test_folder, 'lisa')\n",
    "test_moe = os.path.join(test_folder, 'moe')\n",
    "test_ned = os.path.join(test_folder, 'ned')\n",
    "test_krusty = os.path.join(test_folder, 'krusty')\n",
    "test_skinner = os.path.join(test_folder, 'skinner')\n",
    "test_charles = os.path.join(test_folder, 'charles')\n",
    "test_milhouse = os.path.join(test_folder, 'milhouse')\n",
    "test_other = os.path.join(test_folder, 'other')\n",
    "\n",
    "val_folder = os.path.join(new_dir, 'val')\n",
    "val_bart = os.path.join(val_folder, 'bart')\n",
    "val_homer = os.path.join(val_folder, 'homer')\n",
    "val_marge = os.path.join(val_folder, 'marge')\n",
    "val_lisa = os.path.join(val_folder, 'lisa')\n",
    "val_moe = os.path.join(val_folder, 'moe')\n",
    "val_ned = os.path.join(val_folder, 'ned')\n",
    "val_krusty = os.path.join(val_folder, 'krusty')\n",
    "val_skinner = os.path.join(val_folder, 'skinner')\n",
    "val_charles = os.path.join(val_folder, 'charles')\n",
    "val_milhouse = os.path.join(val_folder, 'milhouse')\n",
    "val_other = os.path.join(val_folder, 'other')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(train_folder)\n",
    "# os.mkdir(train_bart)\n",
    "# os.mkdir(train_homer)\n",
    "# os.mkdir(train_lisa)\n",
    "# os.mkdir(train_moe)\n",
    "# os.mkdir(train_ned)\n",
    "# os.mkdir(train_krusty)\n",
    "# os.mkdir(train_skinner)\n",
    "# os.mkdir(train_charles)\n",
    "# os.mkdir(train_milhouse)\n",
    "# os.mkdir(train_other)\n",
    "\n",
    "# os.mkdir(test_folder)\n",
    "# os.mkdir(test_bart)\n",
    "# os.mkdir(test_homer)\n",
    "# os.mkdir(test_lisa)\n",
    "# os.mkdir(test_moe)\n",
    "# os.mkdir(test_ned)\n",
    "# os.mkdir(test_krusty)\n",
    "# os.mkdir(test_skinner)\n",
    "# os.mkdir(test_charles)\n",
    "# os.mkdir(test_milhouse)\n",
    "# os.mkdir(test_other)\n",
    "\n",
    "# os.mkdir(val_folder)\n",
    "# os.mkdir(val_bart)\n",
    "# os.mkdir(val_homer)\n",
    "# os.mkdir(val_lisa)\n",
    "# os.mkdir(val_moe)\n",
    "# os.mkdir(val_ned)\n",
    "# os.mkdir(val_krusty)\n",
    "# os.mkdir(val_skinner)\n",
    "# os.mkdir(val_charles)\n",
    "# os.mkdir(val_milhouse)\n",
    "# os.mkdir(val_other)\n",
    "\n",
    "os.mkdir(train_marge)\n",
    "os.mkdir(test_marge)\n",
    "os.mkdir(val_marge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(test_imgs_bart))\n",
    "# print(len(test_imgs_homer))\n",
    "# print(len(test_imgs_marge))\n",
    "# print(len(test_imgs_lisa))\n",
    "# print(len(test_imgs_moe))\n",
    "# print(len(test_imgs_ned))\n",
    "# print(len(test_imgs_krusty))\n",
    "# print(len(test_imgs_skinner))\n",
    "# print(len(test_imgs_charles))\n",
    "# print(len(test_imgs_milhouse))\n",
    "# print(len(test_imgs_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_imgs_bart[150:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/bart_simpson/', img)\n",
    "    destination = os.path.join(train_bart, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_imgs_homer[150:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/homer_simpson/', img)\n",
    "    destination = os.path.join(train_homer, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_imgs_marge[150:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/marge_simpson/', img)\n",
    "    destination = os.path.join(train_marge, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_imgs_lisa[150:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/lisa_simpson/', img)\n",
    "    destination = os.path.join(train_lisa, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_imgs_moe[150:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/moe_szyslak/', img)\n",
    "    destination = os.path.join(train_moe, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_imgs_ned[150:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/ned_flanders/', img)\n",
    "    destination = os.path.join(train_ned, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_imgs_krusty[150:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/krusty_the_clown/', img)\n",
    "    destination = os.path.join(train_krusty, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_imgs_skinner[150:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/principal_skinner/', img)\n",
    "    destination = os.path.join(train_skinner, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_imgs_charles[150:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/charles_montgomery_burns/', img)\n",
    "    destination = os.path.join(train_charles, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_imgs_milhouse[150:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/milhouse_van_houten/', img)\n",
    "    destination = os.path.join(train_milhouse, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_imgs_bart[:250]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/bart_simpson/', img)\n",
    "    destination = os.path.join(val_bart, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = train_imgs_homer[:250]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/homer_simpson/', img)\n",
    "    destination = os.path.join(val_homer, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = train_imgs_marge[:250]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/marge_simpson/', img)\n",
    "    destination = os.path.join(val_marge, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = train_imgs_lisa[:250]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/lisa_simpson/', img)\n",
    "    destination = os.path.join(val_lisa, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "\n",
    "imgs = train_imgs_moe[:250]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/moe_szyslak/', img)\n",
    "    destination = os.path.join(val_moe, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = train_imgs_ned[:250]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/ned_flanders/', img)\n",
    "    destination = os.path.join(val_ned, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = train_imgs_krusty[:250]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/krusty_the_clown/', img)\n",
    "    destination = os.path.join(val_krusty, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "\n",
    "imgs = train_imgs_skinner[:250]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/principal_skinner/', img)\n",
    "    destination = os.path.join(val_skinner, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "\n",
    "imgs = train_imgs_charles[:250]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/charles_montgomery_burns/', img)\n",
    "    destination = os.path.join(val_charles, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    250\n",
    "imgs = train_imgs_milhouse[:250]\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpsons_training_set/milhouse_van_houten/', img)\n",
    "    destination = os.path.join(val_milhouse, img)\n",
    "    shutil.copyfile(origin, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = test_imgs_bart\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpson_test_set/', img)\n",
    "    destination = os.path.join(test_bart, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = test_imgs_homer\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpson_test_set/', img)\n",
    "    destination = os.path.join(test_homer, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = test_imgs_marge\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpson_test_set/', img)\n",
    "    destination = os.path.join(test_marge, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = test_imgs_lisa\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpson_test_set/', img)\n",
    "    destination = os.path.join(test_lisa, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "\n",
    "imgs = test_imgs_moe\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpson_test_set/', img)\n",
    "    destination = os.path.join(test_moe, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = test_imgs_ned\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpson_test_set/', img)\n",
    "    destination = os.path.join(test_ned, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = test_imgs_krusty\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpson_test_set/', img)\n",
    "    destination = os.path.join(test_krusty, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "\n",
    "imgs = test_imgs_skinner\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpson_test_set/', img)\n",
    "    destination = os.path.join(test_skinner, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "\n",
    "imgs = test_imgs_charles\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpson_test_set/', img)\n",
    "    destination = os.path.join(test_charles, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = test_imgs_milhouse\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpson_test_set/', img)\n",
    "    destination = os.path.join(test_milhouse, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = test_imgs_other\n",
    "for img in imgs:\n",
    "    origin = os.path.join('simpson_test_set/', img)\n",
    "    destination = os.path.join(test_other, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_images_other[150:]\n",
    "character_train = ['charles_montgomery_burns','milhouse_van_houten','moe_szyslak','ned_flanders','krusty_the_clown','marge_simpson','principal_skinner','bart_simpson','lisa_simpson', 'homer_simpson','.DS_Store']\n",
    "for folder in os.listdir('simpsons_training_set/'):\n",
    "    if folder not in character_train:\n",
    "        for img in imgs:\n",
    "            if img in os.listdir('simpsons_training_set/'+folder):\n",
    "                origin = os.path.join('simpsons_training_set/'+folder,img)\n",
    "                destination = os.path.join(train_other,img)\n",
    "                shutil.copyfile(origin, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_images_other[:250]\n",
    "character_train = ['charles_montgomery_burns','milhouse_van_houten','moe_szyslak','ned_flanders','krusty_the_clown','marge_simpson','principal_skinner','bart_simpson','lisa_simpson', 'homer_simpson','.DS_Store']\n",
    "for folder in os.listdir('simpsons_training_set/'):\n",
    "    if folder not in character_train:\n",
    "        for img in imgs:\n",
    "            if img in os.listdir('simpsons_training_set/'+folder):\n",
    "                origin = os.path.join('simpsons_training_set/'+folder,img)\n",
    "                destination = os.path.join(val_other,img)\n",
    "                shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 990 images belonging to 11 classes.\n",
      "Found 2622 images belonging to 11 classes.\n",
      "Found 13286 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=(64, 64), batch_size = 32) \n",
    "\n",
    "# get all the data in the directory split/validation (200 images), and reshape them\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, \n",
    "        target_size=(64, 64), batch_size = 32)\n",
    "\n",
    "# get all the data in the directory split/train (542 images), and reshape them\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_folder, \n",
    "        target_size=(64, 64), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 85/416 [=====>........................] - ETA: 2:37 - loss: 1.9944 - acc: 0.3360"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-82ebe09f379a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m cnn_history = model.fit_generator(train_generator,\n\u001b[1;32m     32\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     validation_data=val_generator)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(64 ,64,  3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(11, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['acc'])\n",
    "\n",
    "filepath = \"model_0.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "cnn_history = model.fit_generator(train_generator,\n",
    "                    epochs=30,\n",
    "                    validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
